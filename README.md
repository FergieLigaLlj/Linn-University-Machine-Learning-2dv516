### Attribution of different jupyter notebooks to the corresponding assignments and their learning expectation:

1 Neural networks:
Exercise 1a: Fashion MNIST: Train a multilayer perceptron, by ----**learning rate**, **number of and size of hidden layers**, **activation function and regularization** (e.g. Ridge (known here as L2), and **early stopping**
Exercise 1b: Fashion MNIST analysis and further extension: **confusion matrix** with mix, evaluation of legitimacy of **misinterpretation** by comparison inspection
Exercise 2: Neural networks from scratch: one single hidden-layer **pseudocode**

2 Ensemble methods and Decision Trees:
Exercise 3: Ensemble of Batman Trees: decision tree **subset** training and **majority vote**, **bootstrap technique** in sampling, decision boundary of both **ensemble and major vote**

3 Support vector machines

Exercise 4 :Various kernels: **Tune the parameter** for best model selection: ![image](https://github.com/user-attachments/assets/e58b2f25-83d2-4a54-9429-534a3e567f5d), 
**decision boundary comparison** with true model.

Exercise 5: Implicit versus explicit: explicit model: **svm.SVC(kernel = ’linear’)** and **mapFeature** function; implicit: **svm.SVC(kernel = ’poly’, degree = d)**

Exercise 6: One versus all MNIST: **rbf-kernels** performance optimization by **cross-validation**, comparison between **one-vs-one** and **one-vs-all** with **confusion matrix** again
